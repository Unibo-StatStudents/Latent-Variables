---
title: "Lab 1 - Exercise 2"
output: github_document
author: "Sebastian Veuskens"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries 
## Load libraries 

```{r}
library(lavaan)         # For Holzinger data 
library(GPArotation)    # For Factor rotations 
library(ltm)            # For Abortion data and Item response theory 
library(poLCA)          # For latent class analysis 
```

## Load data 

```{r}
data(HolzingerSwineford1939)
data(Abortion)
data(carcinoma)
data(Mobility)
scitec <- read.table("Lab 3/Example UVA/scie7i.dat", header=F)
socmob <- read.table("socmob.txt")
```

## 2

```{r}
cov_mat <- as.matrix(socmob)                        # Alternative for data if only covariance/correlation matrix is given
heatmap(cov_mat)

```

```{r}
n_obs <- 713                                     # Number of observations, only needed if cov_mat is used instead of data 
formula_nlf <- ~V1+V2+V3+V4+V5+V6+V7+V8+V9+V10      # Variables to include into the analysis (response variables)
n_facs <- c(1, 2, 3, 4)                            # Vector of numbers of factors to be used 
cut_off <- 0.2                                  # Correlation threshold onto which not to include in the factor loadings 
n_items <- ncol(cov_mat)                           # The number of items p included into the analysis 
fac_score_method <- "Bartlett"                  # Alternative: "regression" -> Used method to calculate individual scores 
formula_cfa <- 'f1 =~ V3 + V4 + V6 + V7
                f2 =~ V1 + V2 + V5 + V10
                f3 =~ V8 + V9 + V10'          # Connect factors and manifest variables manually (create your own loadings matrix) 
#################

## ML-estimation of factor model 
chi_sq <- list() 
df <- list() 
p_value <- list() 
fac_models <- list() 
for (n_fac in n_facs) {
    # fac_model_cand <- factanal(x = formula_nlf, factors = n_fac, data = data, scores = fac_score_method)
    fac_model_cand <- factanal(x = formula_nlf, factors = n_fac, covmat = cov_mat, n.obs=n_obs, rotation='none')
    fac_models[[n_fac]] <- fac_model_cand 
    chi_sq[[n_fac]] <- fac_model_cand$STATISTIC
    df[[n_fac]] <- fac_model_cand$dof 
    p_value[[n_fac]] <- fac_model_cand$PVAL
}
round(unlist(p_value), 5)
best_n_fac <- n_facs[which.max(unlist(p_value))]
fac_model <- fac_models[[best_n_fac]]
fac_model <- fac_models[[3]]

## Model statistics 

chi_sq[[best_n_fac]]
df[[best_n_fac]]
p_value[[best_n_fac]]

```

## 3

```{r}
# Communalities -> Percentage of variability explained by factors for each manifest variable/item/indicator (x_i) 
commun <- rowSums(loadings(fac_model)^2)        # Alternatively: commun <- 1 - fac_model$uniquenesses 
1 - fac_model$uniquenesses 
commun
# Total explained variance 
perc_var <- sum(commun) / n_items 
perc_var
```

## 4

```{r}
## Reproduced correlation matrix 
rep_corr <- loadings(fac_model) %*% t(loadings(fac_model)) 
rep_corr
## Discrepancy matrix 
round(cov_mat - rep_corr, 3)          
```

## 5

```{r}
# Orthogonal rotations 
Varimax(loadings(fac_model))                    # Factors with few large and many near zero loadings 
quartimax(loadings(fac_model))                  # Aims at the correspondence between observed and latent factors 
# Oblique rotations 
promax(loadings(fac_model))                     # Simple structure with low correlation between factors 
oblimin(loadings(fac_model))                    # Similar to Varimax (few large and many zero), but oblique rotation 

# Display loadings for confimatory analysis formula 
heatmap(Varimax(loadings(fac_model))$loadings, scale='none')
heatmap(quartimax(loadings(fac_model))$loadings, scale='none')
heatmap(promax(loadings(fac_model))$loadings, scale='none')
heatmap(oblimin(loadings(fac_model))$loadings, scale='none')

```

## 6 

```{r}
#### Confirmatory analysis 
# std.lv (variance standardization) -> Standard loading variances, means that the variance for all factors is set to one 
# The default alternative is the marker method 
# orthogonal indicates the Covariance matrix of the factors: If true, all factors will be uncorrelated 
# orthogonal decreases the number of free model parameters 
# cfa_model <- cfa(formula_cfa, data = data, std.lv = TRUE, orthogonal = FALSE) 
cfa_model <- cfa(formula_cfa, sample.cov=cov_mat, sample.nobs=n_obs, std.lv = TRUE) 
summary(cfa_model, fit.measures = TRUE)
# CFI: should be over 0.8 or 0.9
# TLI: should be over 0.8 or 0.9
# RMSEA: should lower than 0.08 
# The baseline model is a model that just estimates the p variances of the 
# items and assumes all Covariances as 0 -> assumes independence of items 
```

## 2

```{r}

```

## 2

```{r}

```

## 2

```{r}

```